# Draw a preprocessed dataset directly from my HF profile.
# This dataset is already tokenized, you "have" to load the correct tokenizer
name: pile-readymade
sources:
  hub:
    provider: hub
hf_location: JonasGeiping/the_pile_WordPiecex32768_97b8e776baafb99c3892e6572a9f51b3
streaming: True

vocab_size: 32768 # cannot be changed!
seq_length: 128 # cannot be changed!
